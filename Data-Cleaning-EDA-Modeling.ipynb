{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re, numpy as np, pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Gensim\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define stopwords\n",
    "punctuation = \"\".join([symbol for symbol in string.punctuation if symbol not in [\"'\", '\"']])\n",
    "punctuation += '–'\n",
    "punctuation += '...'\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list += list(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " '!',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '–',\n",
       " '.',\n",
       " '.',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking my list of stopwords\n",
    "stopwords_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dataframes\n",
    "df = pd.read_pickle('script_TM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1086, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMPUTER SCREEN</td>\n",
       "      <td>So close it has no boundaries. A blinking cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAN (V.O.)</td>\n",
       "      <td>Hello? Data now slashes across the screen, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCREEN</td>\n",
       "      <td>Call trans opt:  received.   2-19-96  13:24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WOMAN (V.O.)</td>\n",
       "      <td>I'm inside.  Anything to report? We listen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRINITY.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CYPHER (V.O.)</td>\n",
       "      <td>Let's see.  Target left work at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5:01 PM.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SCREEN</td>\n",
       "      <td>Trace program:  running. The entire screen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CYPHER (V.O.)</td>\n",
       "      <td>He caught the northbound Howard    line. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TRINITY (V.O.)</td>\n",
       "      <td>All right, you're relieved.  Use   the usua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CYPHER (V.O.)</td>\n",
       "      <td>Do you know when we're going to   make cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TRINITY</td>\n",
       "      <td>Soon. Only two thin digits left.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CYPHER (V.O.)</td>\n",
       "      <td>Just between you and me, you don't    belie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TRINITY (V.O.)</td>\n",
       "      <td>I think Morpheus believes he is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CYPHER (V.O.)</td>\n",
       "      <td>I know.  But what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TRINITY (V.O.)</td>\n",
       "      <td>I think Morpheus knows things that   I don't.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CYPHER (V.O.)</td>\n",
       "      <td>Yeah, but if he's wrong -- The final number...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRINITY (V.O.)</td>\n",
       "      <td>Did you hear that?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CYPHER (V.O.)</td>\n",
       "      <td>Hear what?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SCREEN</td>\n",
       "      <td>Trace complete.  Call origin:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>#312-555-0690</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TRINITY (V.O.)</td>\n",
       "      <td>Are you sure this line is clean?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CYPHER (V.O.)</td>\n",
       "      <td>Yeah, course I'm sure. We MOVE STILL CLOSER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TRINITY (V.O.)</td>\n",
       "      <td>I better go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CYPHER (V.O.)</td>\n",
       "      <td>Yeah.  Right.  See you on the other side. S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Speaker                                               Text\n",
       "0       COMPUTER SCREEN   So close it has no boundaries. A blinking cur...\n",
       "1            MAN (V.O.)     Hello? Data now slashes across the screen, ...\n",
       "2                SCREEN     Call trans opt:  received.   2-19-96  13:24...\n",
       "3          WOMAN (V.O.)     I'm inside.  Anything to report? We listen ...\n",
       "4              TRINITY.                                                   \n",
       "5         CYPHER (V.O.)                    Let's see.  Target left work at\n",
       "6              5:01 PM.                                                   \n",
       "7                SCREEN     Trace program:  running. The entire screen ...\n",
       "8         CYPHER (V.O.)     He caught the northbound Howard    line. Go...\n",
       "9        TRINITY (V.O.)     All right, you're relieved.  Use   the usua...\n",
       "10        CYPHER (V.O.)     Do you know when we're going to   make cont...\n",
       "11              TRINITY                   Soon. Only two thin digits left.\n",
       "12        CYPHER (V.O.)     Just between you and me, you don't    belie...\n",
       "13       TRINITY (V.O.)                   I think Morpheus believes he is.\n",
       "14        CYPHER (V.O.)                       I know.  But what about you?\n",
       "15       TRINITY (V.O.)      I think Morpheus knows things that   I don't.\n",
       "16        CYPHER (V.O.)     Yeah, but if he's wrong -- The final number...\n",
       "17       TRINITY (V.O.)                                 Did you hear that?\n",
       "18        CYPHER (V.O.)                                         Hear what?\n",
       "19               SCREEN                      Trace complete.  Call origin:\n",
       "20        #312-555-0690                                                   \n",
       "21       TRINITY (V.O.)                   Are you sure this line is clean?\n",
       "22        CYPHER (V.O.)     Yeah, course I'm sure. We MOVE STILL CLOSER...\n",
       "23       TRINITY (V.O.)                                       I better go.\n",
       "24       CYPHER (V.O.)      Yeah.  Right.  See you on the other side. S..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     NEO               175\n",
       "     MORPHEUS          134\n",
       "     TRINITY           120\n",
       "     AGENT SMITH        73\n",
       "     TANK               60\n",
       "                      ... \n",
       " INT. MAIN DECK          1\n",
       " INT.  CAR               1\n",
       "   #312-555-0690         1\n",
       " ON COMPUTER SCREEN      1\n",
       " EXT.  EL TRAIN          1\n",
       "Name: Speaker, Length: 156, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Speaker.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Speaker.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' COMPUTER SCREEN', '     MAN (V.O.)', '     SCREEN',\n",
       "       '     WOMAN (V.O.)', ' TRINITY.', '     CYPHER (V.O.)',\n",
       "       '   5:01 PM.', '     TRINITY (V.O.)', '     TRINITY',\n",
       "       '   #312-555-0690', '     CYPHER (V.O.) ', '     RADIO (V.O.)',\n",
       "       ' INT.  CHASE HOTEL - NIGHT', '     BIG COP',\n",
       "       ' EXT.  CHASE HOTEL - NIGHT', '     AGENT SMITH',\n",
       "       '     LIEUTENANT', '     AGENT SMITH ', ' INT.  CHASE HOTEL',\n",
       "       ' FIRES --', ' EXT.  CHASE HOTEL', '     MORPHEUS (V.O.)',\n",
       "       ' INT.  HALL', ' EXT.  FIRE E5CAPE', ' EXT.  ROOF', '     COP',\n",
       "       ' EXT.  STREET', '     AGENT JONES', '   FOS4:  ALL HAIL SEGA!!!',\n",
       "       \" INT.  NEO'S APARTMENT\", '     NEO', '     VOICE (O.S.)',\n",
       "       '     ANTHONY', '     DUJOUR', ' INT.  APARTMENT',\n",
       "       '       CUT TO:', ' 9:15 A.M.', ' EXT.  SKYSCRAPER',\n",
       "       ' INT.  CORTECHS OFFICE', '     RHINEHEART',\n",
       "       \" INT.  NEO'S CUBICLE\", '     TALL EMPLOYEE', '     FEDEX',\n",
       "       ' INT.  INTERROGATION ROOM - CLOSE ON CAMERA MONITOR', ' A.\"',\n",
       "       \" INT.  NEO'S APARTMENT - NIGHT\", '     MORPHEUS (V.O.).',\n",
       "       ' EXT.  EL TRAIN', ' INT.  TRAIN', '     APOC', ' INT.  TRUCK BED',\n",
       "       ' EXT.  LOWER WACKER', '     GIZMO', ' INT.  VAN',\n",
       "       ' INT.  HOTEL LAFAYETTE', ' INT.  ROOM 1313', '     MORPHEUS',\n",
       "       '     CYPHER', \" INT.  POWER PLANT - CLOSE ON MAN'S BODY\",\n",
       "       ' INT.  WASTE LINE', ' INT.  HOVERCRAFT',\n",
       "       '         FADE TO BLACK.', '     MAN (O.S.)', '     WOMAN (O.S.)',\n",
       "       ' FADE IN:', \" NEO'S POV\", ' ANGLE ON NEO', '     DOZER',\n",
       "       \" INT.  NEO'S ROOM\", ' INT.  MAIN DECK', ' INT.  CONSTRUCT',\n",
       "       '     TANK',\n",
       "       ' INT.  MAIN DECK - CLOSE ON COMPUTER MONITOR - LATER',\n",
       "       ' INT.  DOJO', ' --', ' INT.  MESS HALL', '     MOUSE',\n",
       "       '     CABLE', '     SWITCH', ' EXT.  ROOFTOP', '     CYPHER,',\n",
       "       ' INT.  RESTAURANT (MATRIX) - NIGHT', '   R.S.I.', '   E.M.P?',\n",
       "       ' EXT.  CHICAGO (MATRIX) - DAY',\n",
       "       ' INT.  HOTEL LAFAYETTE (MATRIX) - DAY',\n",
       "       ' INT.  STAIRWELL (MATRIX) - DAY',\n",
       "       ' EXT.  HOTEL LAFAYETTE (MATRIX) - DAY',\n",
       "       ' INT.  LINCOLN CONTINENTAL (MATRIX) - DAY', '     MOJO',\n",
       "       ' EXT.  BAR (MATRIX) - DAY', ' INT.  BAR (MATRIX) - DAY',\n",
       "       '     REX', ' INT.  BASEMENT (MATRIX) - DAY',\n",
       "       ' INT.  TEMPLE OF ZION (MATRIX) - DAY', '     PRIESTESS',\n",
       "       ' INT.  ROOM OF POTENTIALS (MATRIX) - DAY', '     SPOON BOY',\n",
       "       ' INT.  SHRINE (MATRIX) - DAY',\n",
       "       \" INT.  ORACLE'S CHAMBERS (MATRIX) - DAY\", '     ORACLE (WOMAN)',\n",
       "       '     ORACLE', ' INT.  ANTECHAMBER (MATRIX) - DAY',\n",
       "       ' EXT.  CITY STREET (MATRIX) - DAY',\n",
       "       ' INT.  ROOM 1313 (MATRIX) - DAY', '     TANK (V.O.)',\n",
       "       ' INT.  STAIRCASE (MATRIX) - DAY', ' INT.  HALL (MATRIX) - DAY',\n",
       "       ' INT.  STAIRS (MATRIX) - DAY', ' INT.  LAFAYETTE (MATRIX) - DAY',\n",
       "       ' INT.  ROOM 808 (MATRIX) - DAY', '     AGENT BROWTJ',\n",
       "       ' INT.  WALL (MATRIX) - DAY', '     AGENT BROWN',\n",
       "       ' INT.  ROOM 608 (MATRIX) - DAY',\n",
       "       ' INT.  CATCH BASIN (MATRIX) - DAY',\n",
       "       ' INT.  SEWER MAIN (MATRIX) - DAY', '     COPS',\n",
       "       ' EXT.  STREET (MATRIX) - DAY', '    MORPHEUS',\n",
       "       ' INT.  APPLIANCE STORE (MATRIX) - DAY', ' INT. MAIN DECK',\n",
       "       ' EXT.  NIKO HOTEL (MATRIX) - DAY',\n",
       "       ' INT.  TOP FLOOR (MATRIX) - DAY',\n",
       "       ' INT.  PRESIDENTIAL SUITE (MATRIX) - DAY',\n",
       "       ' INT.  NIKO HOTEL (MATRIX) - DAY',\n",
       "       ' INT.  ELEVATORS (MATRIX) - DAY',\n",
       "       ' INT.  ELEVATOR SHAFT (MATRIX) - DAY',\n",
       "       ' INT.  LOBBY (MATRIX) - DAY', ' BA-BOOM!',\n",
       "       ' EXT.  ROOF (MATRIX) - DAY', '     PILOT', '     SERGEANT',\n",
       "       ' INTO VIEW --', ' FIRE.', ' HELICOPTER BEGIN TO DIE.',\n",
       "       ' EXT.  ROOFTOP (MATRIX) - DAY',\n",
       "       ' INT.  \"EL\" STATION (MATRIX) - DAY', '     OLD MAN', ' CLICK.',\n",
       "       ' INT.  SEWER MAIN', ' INT.  CAR (MATRIX) - DAY',\n",
       "       '     NEO (V.O.)', ' INT.  CAR',\n",
       "       ' INT.  \"HEART OF CHICAGO\" HOTEL (MATRIX) - DAY',\n",
       "       ' EXT.  ALLEY (MATRIX) - DAY', ' 305...  304...', ' BOOM.',\n",
       "       ' INT.  HOTEL HALL (MATRIX) - DAY',\n",
       "       ' INT.  ROOM 303 (MATRIX) - DAY', ' INT.  OVERFLOW PIT',\n",
       "       ' ON COMPUTER SCREEN', '     BOY', '     MOMMY',\n",
       "       '          FADE OUT.', '     THE END'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Speaker.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I need to remove all the V.O to keep only the names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use split to take the V.O at the end of the in the Speaker name\n",
    "df.Speaker = df.Speaker.apply(lambda x: x.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1086, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMPUTER</td>\n",
       "      <td>So close it has no boundaries. A blinking cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAN</td>\n",
       "      <td>Hello? Data now slashes across the screen, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCREEN</td>\n",
       "      <td>Call trans opt:  received.   2-19-96  13:24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WOMAN</td>\n",
       "      <td>I'm inside.  Anything to report? We listen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRINITY.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CYPHER</td>\n",
       "      <td>Let's see.  Target left work at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5:01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SCREEN</td>\n",
       "      <td>Trace program:  running. The entire screen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CYPHER</td>\n",
       "      <td>He caught the northbound Howard    line. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TRINITY</td>\n",
       "      <td>All right, you're relieved.  Use   the usua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CYPHER</td>\n",
       "      <td>Do you know when we're going to   make cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TRINITY</td>\n",
       "      <td>Soon. Only two thin digits left.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CYPHER</td>\n",
       "      <td>Just between you and me, you don't    belie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TRINITY</td>\n",
       "      <td>I think Morpheus believes he is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CYPHER</td>\n",
       "      <td>I know.  But what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TRINITY</td>\n",
       "      <td>I think Morpheus knows things that   I don't.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CYPHER</td>\n",
       "      <td>Yeah, but if he's wrong -- The final number...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRINITY</td>\n",
       "      <td>Did you hear that?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CYPHER</td>\n",
       "      <td>Hear what?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SCREEN</td>\n",
       "      <td>Trace complete.  Call origin:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>#312-555-0690</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TRINITY</td>\n",
       "      <td>Are you sure this line is clean?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CYPHER</td>\n",
       "      <td>Yeah, course I'm sure. We MOVE STILL CLOSER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TRINITY</td>\n",
       "      <td>I better go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CYPHER</td>\n",
       "      <td>Yeah.  Right.  See you on the other side. S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Speaker                                               Text\n",
       "0        COMPUTER   So close it has no boundaries. A blinking cur...\n",
       "1             MAN     Hello? Data now slashes across the screen, ...\n",
       "2          SCREEN     Call trans opt:  received.   2-19-96  13:24...\n",
       "3           WOMAN     I'm inside.  Anything to report? We listen ...\n",
       "4        TRINITY.                                                   \n",
       "5          CYPHER                    Let's see.  Target left work at\n",
       "6            5:01                                                   \n",
       "7          SCREEN     Trace program:  running. The entire screen ...\n",
       "8          CYPHER     He caught the northbound Howard    line. Go...\n",
       "9         TRINITY     All right, you're relieved.  Use   the usua...\n",
       "10         CYPHER     Do you know when we're going to   make cont...\n",
       "11        TRINITY                   Soon. Only two thin digits left.\n",
       "12         CYPHER     Just between you and me, you don't    belie...\n",
       "13        TRINITY                   I think Morpheus believes he is.\n",
       "14         CYPHER                       I know.  But what about you?\n",
       "15        TRINITY      I think Morpheus knows things that   I don't.\n",
       "16         CYPHER     Yeah, but if he's wrong -- The final number...\n",
       "17        TRINITY                                 Did you hear that?\n",
       "18         CYPHER                                         Hear what?\n",
       "19         SCREEN                      Trace complete.  Call origin:\n",
       "20  #312-555-0690                                                   \n",
       "21        TRINITY                   Are you sure this line is clean?\n",
       "22         CYPHER     Yeah, course I'm sure. We MOVE STILL CLOSER...\n",
       "23        TRINITY                                       I better go.\n",
       "24         CYPHER     Yeah.  Right.  See you on the other side. S..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COMPUTER',\n",
       " 'MAN',\n",
       " 'SCREEN',\n",
       " 'WOMAN',\n",
       " 'TRINITY.',\n",
       " 'CYPHER',\n",
       " '5:01',\n",
       " 'TRINITY',\n",
       " '#312-555-0690',\n",
       " 'RADIO',\n",
       " 'INT.',\n",
       " 'BIG',\n",
       " 'EXT.',\n",
       " 'AGENT',\n",
       " 'LIEUTENANT',\n",
       " 'FIRES',\n",
       " 'MORPHEUS',\n",
       " 'COP',\n",
       " 'FOS4:',\n",
       " 'NEO',\n",
       " 'VOICE',\n",
       " 'ANTHONY',\n",
       " 'DUJOUR',\n",
       " 'CUT',\n",
       " '9:15',\n",
       " 'RHINEHEART',\n",
       " 'TALL',\n",
       " 'FEDEX',\n",
       " 'A.\"',\n",
       " 'APOC',\n",
       " 'GIZMO',\n",
       " 'FADE',\n",
       " \"NEO'S\",\n",
       " 'ANGLE',\n",
       " 'DOZER',\n",
       " 'TANK',\n",
       " '--',\n",
       " 'MOUSE',\n",
       " 'CABLE',\n",
       " 'SWITCH',\n",
       " 'CYPHER,',\n",
       " 'R.S.I.',\n",
       " 'E.M.P?',\n",
       " 'MOJO',\n",
       " 'REX',\n",
       " 'PRIESTESS',\n",
       " 'SPOON',\n",
       " 'ORACLE',\n",
       " 'COPS',\n",
       " 'BA-BOOM!',\n",
       " 'PILOT',\n",
       " 'SERGEANT',\n",
       " 'INTO',\n",
       " 'FIRE.',\n",
       " 'HELICOPTER',\n",
       " 'OLD',\n",
       " 'CLICK.',\n",
       " '305...',\n",
       " 'BOOM.',\n",
       " 'ON',\n",
       " 'BOY',\n",
       " 'MOMMY',\n",
       " 'THE']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.Speaker.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "#         sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
    "        sent = re.sub('\\t', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub('\\n', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['so', 'close', 'it', 'has', 'no', 'boundaries', 'blinking', 'cursor', 'pulses', 'in', 'the', 'electric', 'darkness', 'like', 'heart', 'coursing', 'with', 'phosphorous', 'light', 'burning', 'beneath', 'the', 'derma', 'of', 'black', 'neon', 'glass', 'phone', 'begins', 'to', 'ring', 'we', 'hear', 'it', 'as', 'though', 'we', 'were', 'making', 'the', 'call', 'the', 'cursor', 'continues', 'to', 'throb', 'relentlessly', 'patient', 'until']]\n"
     ]
    }
   ],
   "source": [
    "# Convert to list\n",
    "data = df.Text.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Bigram, Trigram Models and Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# !python3 -m spacy download en  # run in terminal once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_words(texts, stop_words=stopwords_list, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    texts_out = []\n",
    "    nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    # remove stopwords once more after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready = process_words(data_words)  # processed the entire movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['close',\n",
       "  'boundary',\n",
       "  'blink',\n",
       "  'cursor',\n",
       "  'pulse',\n",
       "  'electric',\n",
       "  'darkness',\n",
       "  'heart',\n",
       "  'course',\n",
       "  'phosphorous',\n",
       "  'light',\n",
       "  'burn',\n",
       "  'black',\n",
       "  'neon',\n",
       "  'glass',\n",
       "  'phone',\n",
       "  'begin',\n",
       "  'ring',\n",
       "  'hear',\n",
       "  'make',\n",
       "  'call',\n",
       "  'continue',\n",
       "  'relentlessly',\n",
       "  'patient']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ready[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data_ready)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=6, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=10,\n",
    "                                           passes=10,\n",
    "                                           alpha='symmetric',\n",
    "                                           iterations=100,\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.059*\"phone\" + 0.048*\"open\" + 0.026*\"ring\" + 0.026*\"door\" + 0.024*\"car\" + 0.021*\"find\" + 0.020*\"agent_jone\" + 0.016*\"drop\" + 0.016*\"helicopter\" + 0.016*\"take\"')\n",
      "--------\n",
      "(1, '0.063*\"go\" + 0.056*\"tank\" + 0.055*\"know\" + 0.042*\"man\" + 0.027*\"start\" + 0.027*\"smile\" + 0.024*\"dead\" + 0.023*\"believe\" + 0.020*\"boy\" + 0.019*\"life\"')\n",
      "--------\n",
      "(2, '0.042*\"see\" + 0.030*\"get\" + 0.030*\"hold\" + 0.027*\"stand\" + 0.026*\"begin\" + 0.025*\"hole\" + 0.025*\"look\" + 0.023*\"eye\" + 0.022*\"let\" + 0.019*\"try\"')\n",
      "--------\n",
      "(3, '0.039*\"agent\" + 0.033*\"fly\" + 0.029*\"stare\" + 0.024*\"back\" + 0.022*\"turn\" + 0.019*\"elevator\" + 0.019*\"machine\" + 0.019*\"metal\" + 0.018*\"still\" + 0.016*\"blow\"')\n",
      "--------\n",
      "(4, '0.037*\"hear\" + 0.025*\"black\" + 0.023*\"close\" + 0.020*\"make\" + 0.019*\"pull\" + 0.018*\"come\" + 0.017*\"ear\" + 0.017*\"beat\" + 0.016*\"old\" + 0.015*\"attack\"')\n",
      "--------\n",
      "(5, '0.061*\"trinity\" + 0.026*\"fall\" + 0.026*\"body\" + 0.026*\"gun\" + 0.024*\"scream\" + 0.019*\"fire\" + 0.019*\"bullet\" + 0.017*\"air\" + 0.016*\"right\" + 0.015*\"shoot\"')\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "#check the topic\n",
    "for topic in lda_model.print_topics():\n",
    "    print(topic)\n",
    "    print(\"--------\")\n",
    "# print(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dominant topic and its percentage contribution in each text/action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6410</td>\n",
       "      <td>hear, black, close, make, pull, come, ear, beat, old, attack</td>\n",
       "      <td>[close, boundary, blink, cursor, pulse, electric, darkness, heart, course, phosphorous, light, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>agent, fly, stare, back, turn, elevator, machine, metal, still, blow</td>\n",
       "      <td>[slash, screen, information, flash, faster, read]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7805</td>\n",
       "      <td>hear, black, close, make, pull, come, ear, beat, old, attack</td>\n",
       "      <td>[call, receive, log]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>phone, open, ring, door, car, find, agent_jone, drop, helicopter, take</td>\n",
       "      <td>[report, listen, phone, conversation, third, line, woman]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>phone, open, ring, door, car, find, agent_jone, drop, helicopter, take</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>see, get, hold, stand, begin, hole, look, eye, let, try</td>\n",
       "      <td>[let, see, target, leave, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>phone, open, ring, door, car, find, agent_jone, drop, helicopter, take</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6710</td>\n",
       "      <td>agent, fly, stare, back, turn, elevator, machine, metal, still, blow</td>\n",
       "      <td>[program, run, entire, screen, fill, race, column, number, shimmer, green, rush, digit, phone, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6566</td>\n",
       "      <td>see, get, hold, stand, begin, hole, look, eye, let, try</td>\n",
       "      <td>[catch, line, get, stop, purchase, pack, return, area, code, identify, first, number, suddenly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.8539</td>\n",
       "      <td>trinity, fall, body, gun, scream, fire, bullet, air, right, shoot</td>\n",
       "      <td>[right, relieved, use, usual, exit]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             4.0              0.6410   \n",
       "1            1             3.0              0.8755   \n",
       "2            2             4.0              0.7805   \n",
       "3            3             0.0              0.4028   \n",
       "4            4             0.0              0.1667   \n",
       "5            5             2.0              0.8611   \n",
       "6            6             0.0              0.1667   \n",
       "7            7             3.0              0.6710   \n",
       "8            8             2.0              0.6566   \n",
       "9            9             5.0              0.8539   \n",
       "\n",
       "                                                                 Keywords  \\\n",
       "0            hear, black, close, make, pull, come, ear, beat, old, attack   \n",
       "1    agent, fly, stare, back, turn, elevator, machine, metal, still, blow   \n",
       "2            hear, black, close, make, pull, come, ear, beat, old, attack   \n",
       "3  phone, open, ring, door, car, find, agent_jone, drop, helicopter, take   \n",
       "4  phone, open, ring, door, car, find, agent_jone, drop, helicopter, take   \n",
       "5                 see, get, hold, stand, begin, hole, look, eye, let, try   \n",
       "6  phone, open, ring, door, car, find, agent_jone, drop, helicopter, take   \n",
       "7    agent, fly, stare, back, turn, elevator, machine, metal, still, blow   \n",
       "8                 see, get, hold, stand, begin, hole, look, eye, let, try   \n",
       "9       trinity, fall, body, gun, scream, fire, bullet, air, right, shoot   \n",
       "\n",
       "                                                                                                  Text  \n",
       "0  [close, boundary, blink, cursor, pulse, electric, darkness, heart, course, phosphorous, light, b...  \n",
       "1                                                    [slash, screen, information, flash, faster, read]  \n",
       "2                                                                                 [call, receive, log]  \n",
       "3                                            [report, listen, phone, conversation, third, line, woman]  \n",
       "4                                                                                                   []  \n",
       "5                                                                      [let, see, target, leave, work]  \n",
       "6                                                                                                   []  \n",
       "7  [program, run, entire, screen, fill, race, column, number, shimmer, green, rush, digit, phone, n...  \n",
       "8  [catch, line, get, stop, purchase, pack, return, area, code, identify, first, number, suddenly, ...  \n",
       "9                                                                  [right, relieved, use, usual, exit]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1086, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's have a look\n",
    "df_dominant_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.270718\n",
       "1.0    0.203499\n",
       "2.0    0.153775\n",
       "5.0    0.132597\n",
       "4.0    0.120626\n",
       "3.0    0.118785\n",
       "Name: Dominant_Topic, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.Dominant_Topic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1086, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most representative action for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Representative Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>phone, open, ring, door, car, find, agent_jone, drop, helicopter, take</td>\n",
       "      <td>[explode, open, heavily, armed, rnen, rush, room]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>go, tank, know, man, start, smile, dead, believe, boy, life</td>\n",
       "      <td>[explain, go, seem, strange, bring, warn, lot, danger]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>see, get, hold, stand, begin, hole, look, eye, let, try</td>\n",
       "      <td>[let, see, target, leave, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9479</td>\n",
       "      <td>agent, fly, stare, back, turn, elevator, machine, metal, still, blow</td>\n",
       "      <td>[company, top, software, company, world, single, employee, understand, part, whole, thus, employ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8741</td>\n",
       "      <td>hear, black, close, make, pull, come, ear, beat, old, attack</td>\n",
       "      <td>[deal, chew, steak, loudly, smack, tooth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9214</td>\n",
       "      <td>trinity, fall, body, gun, scream, fire, bullet, air, right, shoot</td>\n",
       "      <td>[child, separate, possible, impossible, young, mind, easy, free, mind, difficult]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0              0.8957   \n",
       "1        1.0              0.9053   \n",
       "2        2.0              0.8611   \n",
       "3        3.0              0.9479   \n",
       "4        4.0              0.8741   \n",
       "5        5.0              0.9214   \n",
       "\n",
       "                                                                 Keywords  \\\n",
       "0  phone, open, ring, door, car, find, agent_jone, drop, helicopter, take   \n",
       "1             go, tank, know, man, start, smile, dead, believe, boy, life   \n",
       "2                 see, get, hold, stand, begin, hole, look, eye, let, try   \n",
       "3    agent, fly, stare, back, turn, elevator, machine, metal, still, blow   \n",
       "4            hear, black, close, make, pull, come, ear, beat, old, attack   \n",
       "5       trinity, fall, body, gun, scream, fire, bullet, air, right, shoot   \n",
       "\n",
       "                                                                                   Representative Text  \n",
       "0                                                    [explode, open, heavily, armed, rnen, rush, room]  \n",
       "1                                               [explain, go, seem, strange, bring, warn, lot, danger]  \n",
       "2                                                                      [let, see, target, leave, work]  \n",
       "3  [company, top, software, company, world, single, employee, understand, part, whole, thus, employ...  \n",
       "4                                                            [deal, chew, steak, loudly, smack, tooth]  \n",
       "5                    [child, separate, possible, impossible, young, mind, easy, free, mind, difficult]  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Distribution of Word Counts in movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'phone': 0.05897323, 'open': 0.047538627, 'ring': 0.026129488, 'door': 0.025514964, 'car': 0.024185978, 'find': 0.02070577, 'agent_jone': 0.020233853, 'drop': 0.016317, 'helicopter': 0.016171647, 'take': 0.01612897, 'rush': 0.013947997, 'hand': 0.013075812, 'jump': 0.01297167, 'sit': 0.01260833, 'hang': 0.011493117, 'explode': 0.011279634, 'almost': 0.011145089, 'line': 0.010375493, 'shake': 0.009991352, 'monitor': 0.009990843, 'room': 0.009905918, 'slow': 0.009530389, 'cypher': 0.008977997, 'head': 0.00889582, 'key': 0.008863169, 'finger': 0.008726907, 'rope': 0.008410365, 'grab': 0.007723027, 'roof': 0.007323642, 'truck': 0.0069503183}\n",
      "1 {'go': 0.062824585, 'tank': 0.055669684, 'know': 0.055035334, 'man': 0.041758213, 'start': 0.027326284, 'smile': 0.02680533, 'dead': 0.024341457, 'believe': 0.023339152, 'boy': 0.019751703, 'life': 0.018976077, 'think': 0.014551956, 'little': 0.014251259, 'white': 0.012450625, 'want': 0.011761688, 'seem': 0.011715347, 'kiss': 0.011613785, 'thing': 0.010901213, 'win': 0.0090682795, 'search': 0.008984599, 'change': 0.008627052, 'unit': 0.0082784025, 'need': 0.00754829, 'control': 0.0064240424, 'bring': 0.00586403, 'soon': 0.0056799627, 'mean': 0.0055899494, 'matrix': 0.0052903304, 'help': 0.005209677, 'listen': 0.005132692, 'nod': 0.004888359}\n",
      "2 {'see': 0.042109974, 'get': 0.02982695, 'hold': 0.029743697, 'stand': 0.027022913, 'begin': 0.025786484, 'hole': 0.025338784, 'look': 0.025065199, 'eye': 0.02260785, 'let': 0.021898722, 'try': 0.01896194, 'snap': 0.017270513, 'glass': 0.016689992, 'long': 0.015022762, 'darkness': 0.014202585, 'move': 0.012584964, 'time': 0.011720441, 'ready': 0.01152803, 'work': 0.010597644, 'tell': 0.010344968, 'check': 0.010178737, 'reach': 0.009849833, 'stop': 0.009649059, 'die': 0.008140257, 'human': 0.007989915, 'click': 0.0076626125, 'send': 0.007404178, 'build': 0.006334615, 'kick': 0.0062811784, 'surge': 0.006244263, 'continue': 0.0061535905}\n",
      "3 {'agent': 0.03850799, 'fly': 0.033461943, 'stare': 0.028923767, 'back': 0.02431312, 'turn': 0.021703018, 'elevator': 0.019191485, 'machine': 0.01897654, 'metal': 0.018563174, 'still': 0.01786962, 'blow': 0.015772024, 'neo': 0.015052088, 'throw': 0.013068405, 'coat': 0.012966767, 'sound': 0.012714144, 'face': 0.011946902, 'drive': 0.011904756, 'walk': 0.011774712, 'agent_smith': 0.011737856, 'fill': 0.011307603, 'run': 0.011094106, 'screen': 0.01078887, 'touch': 0.010501812, 'dark': 0.010087393, 'speed': 0.0097454, 'pour': 0.009403244, 'train': 0.009288494, 'arm': 0.008886416, 'world': 0.008012407, 'last': 0.007823025, 'soar': 0.007682693}\n",
      "4 {'hear': 0.037055135, 'black': 0.02489164, 'close': 0.023118172, 'make': 0.019840127, 'pull': 0.01913298, 'come': 0.01842802, 'ear': 0.01663328, 'beat': 0.016547196, 'old': 0.01598648, 'attack': 0.014972368, 'laser': 0.014831381, 'call': 0.014565359, 'light': 0.013450416, 'wait': 0.013231501, 'pound': 0.012717126, 'blink': 0.012624241, 'burn': 0.012537696, 'sentinel': 0.012310502, 'piece': 0.011796721, 'deep': 0.011648355, 'program': 0.011615227, 'sign': 0.0111848675, 'hurry': 0.011179514, 'burst': 0.010543708, 'give': 0.0105275335, 'fight': 0.009952213, 'real': 0.009410996, 'track': 0.009334449, 'train': 0.0071533616, 'inside': 0.006484131}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-5fc8a45c6137>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtopic_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopic_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_font_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;31m#     plt.gca().imshow(cloud)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#     plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    508\u001b[0m                                           \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                                           \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                                           font_path=self.font_path))\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0;31m# recompute integral image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-5fc8a45c6137>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m                   \u001b[0mmax_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                   \u001b[0mcolormap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tab10'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                   \u001b[0mcolor_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                   prefer_horizontal=1.0)\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 1. Wordcloud of Top N words in each topic\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# cols = [color for name, color in mcolors.XKCD_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS - mcolors.TABLEAU_COLORS'\n",
    "\n",
    "cols = ['blue','#fd8d49','green','#9e003a']\n",
    "cloud = WordCloud(stopwords=stopwords_list,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=30,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = lda_model.show_topics(formatted=False,num_words=30)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    print(i,topics[i][1])\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=-3, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('topic_wordcloud.png',dpi=180)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
